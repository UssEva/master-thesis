% !TeX spellcheck = en_GB
% !TeX encoding = UTF-8
% !TeX root = ../thesis.tex
\chapter{Related Work}\label{sec:related-work}
The analysis of code in order to obtain information and improve its efficiency and readability is a common method of reducing bug patterns and code smells. These are a few examples of specific ways how researchers try to increase their knowledge about written code and how to get better results in the long term independent of the assessed programming languages.

\section{Analysing \scratch{} Programs}
The tools \drscratch{}~\cite{drscratch} as well as \hairball{}~\cite{hairball} analyse \scratch{} programs to find bugs and code smells. These are then reported to the user in order to improve the computational thinking and coding skills of novice programmers. Bad programming habits were assessed in a preliminary study by Moreno et al.~\cite{badhabits} and code smells that are very common in Scratch were analysed by Vargas-Alba et al.~\cite{badsmells}. Stahlbauer et al.~\cite{whisker} introduced \whisker{} which is a formal testing framework for Scratch. \litterbox{}, a tool created by Fr√§drich et al.~\cite{scratch_bugpatterns} that creates an \AST\ of \scratch{} programs, is used for finding code smells as well as bug patterns.

\section{Object Usage Anomalies}
Interactions with objects are required to follow a specific procedure, for example by a sequence of method calls. But these standards are rarely documented and can lead to problematic behaviour in the code. Wasylkowski et al. ~\cite{object_usage} infers legal sequences of method calls to code examples. The results can then be used to find anomalies in the analysed implementation. As an automatic defect detection algorithm, it is the first of its kind that uses method call sequences to learn and detect anomalies.

\section{N-gram Language Models}
Hindle et al.~\cite{naturalness} first introduced the \ngram{} to show that software source code is highly repetitive and the \ngram{} can be used in code suggestion and completion. This work is the basis for using language models to model source code and demonstrated how they could be used in software tools. A very accurate algorithm by using a Hidden Markov Model for code completion was proposed by Han et al.~\cite{codecompletion}. SLAMC by Nguyen et al.~\cite{SLAMC}, which incorporated semantic information into an n-gram model, presented a method to code suggestion. It demonstrated how tokens can be seen more semantically instead of just syntactically. Raychev et al.~\cite{SLANG} investigated the effectiveness of various language models for code completion, i.e., n-gram and recurrent neural networks. By combining program analysis and the n-gram model, they proposed SLANG which had the goal to predict the sequence of method calls in a software system. 

\section{\bugram{}}
The effective usage of n-gram language models in the field of bug detection is also demonstrated by Wang et al.~\cite{bugram} with their tool \bugram{} that finds defective code with \ngram{s} in \java{} programs. Although there are other studies that covered the usage of n-grams for detecting clone bugs~\cite{clonebugs}, localizing faults~\cite{faults} and code search~\cite{codesearch}, these did not leverage n-gram models. In contrast to n-grams that are only \hyperref[def:token]{\textit{token}} sequences, n-gram models are Markov models built on n-grams.