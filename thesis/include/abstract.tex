% !TeX spellcheck = en_GB
% !TeX encoding = UTF-8
% !TeX root = ../thesis.tex
\chapter*{Abstract}

In contrast to rule-based methods which often rely on special patterns that appear rather frequently in source code, and detect violations based on the inferred rules, the \ngram{} is another approach to bug detection. In this bachelor's thesis, this new way of software bug detection is proposed in order to improve software reliability and the quality of \scratch{} programs. After tokenization, \hyperref[def:token]{\textit{token}} sequences are assessed with their calculated probabilities which are based on the existing model. If a detected \hyperref[def:token]{\textit{token}} sequence has a rather low probability, it gets reported as a potential bug because the assumption is that these kinds of sequential tokens are unusual and should be highlighted to the programmer as a bad practice or programming mistake that affects the program. The \ngram{} gets evaluated in the following ways. First, \scratch{} projects are analysed to find bugs, code smells or unusual use cases. Then the result is compared to the reported bugs by \litterbox{} which assesses the same projects. The \ngram\ reported sequences for each task although \whisker\ tests may have passed and no code smells were found by \litterbox{} which shows the different kind of violations n-gram models are able to detect. Second, detected bugs are categorized to identify if \ngram{s} are suitable for bug detection in \scratch{} projects and if this implementation is able to compete with already existing approaches like \litterbox{}. The project-specific \ngram\ can detect extensions to an original task, which \litterbox\ is not able to do, as well as dead code and empty scripts/bodies, whereas unused variables or long scripts are not in its reported violations. Third, it is analysed if the \ngram\ is able to get valid results with a set of tasks that were openly completed. The analysis demonstrates that this approach of bug detection is even effective in circumstances where solutions of tasks are only fairly related to each other. The project-specific model is still able to identify potential bugs with the exception of the possibility to categorize unusual use cases due to missing reference solutions. Fourth, a comparison between a general \ngram\ and project-specific models showed that the general model out of a big data set is not as useful than project-specific ones. For instance, unusual use cases cannot be detected because of missing reference solutions. To have exact numbers that demonstrate the accuracy of the estimations, further research is needed to give the calculated negative probabilities more meaning. The results suggest that the implementation this bachelor's thesis is referring to is complementary to the above mentioned methods of software analysis.

